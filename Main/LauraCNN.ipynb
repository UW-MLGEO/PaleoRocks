{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b24433",
   "metadata": {},
   "source": [
    "## CNN for Fossil Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013ef96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np \n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import data as tf_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310ae92",
   "metadata": {},
   "source": [
    "We will use transfer learning using different pre-trained models on the imagenet dataset. We first train the Xception model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c91a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create augmented data - Check with Lucy about what we want to do here\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m augmented_data = \u001b[43mtrain_ds\u001b[49m.map(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (data_augmentation(x), y))\n\u001b[32m     15\u001b[39m training_data = training_data.concatenate(augmented_data)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "# Our images are already resized, but we could include optional resizing in the final model\n",
    "# We start with data augmentation\n",
    "augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.25)\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Create augmented data - Check with Lucy about what we want to do here\n",
    "augmented_data = training_data.map(lambda x, y: (data_augmentation(x), y))\n",
    "training_data = training_data.concatenate(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and prefetch data ?\n",
    "\n",
    "batch_size = 64 # this could change\n",
    "\n",
    "training_data = training_data.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "validation_data = validation_data.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "test_data = test_data.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5208152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-03-01 16:04:44.968352: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# We will use transfer learning using different pre-trained models on the imagenet dataset\n",
    "\n",
    "# Create the base model with the pre-trained imagenet weights\n",
    "base_model = keras.applications.Xception(\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (200, 200, 3),\n",
    "    include_top = False) # Why do we not include imagenet at the top? \n",
    "\n",
    "# Freeze the base model weights (they will not be trained)\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that goes on top of the base imagenet model\n",
    "inputs = keras.Input(shape = (200, 200, 3))\n",
    "# We should scale our inputs to be between -1 and 1 (or should we normalize to have mean 0 and std 1?)\n",
    "scale_layer = keras.layers.Rescaling(scale = 1/127.5, offset = -1)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "# We want to keep batchnorm layers of base model in inference (predict) mode so we do not train of them. \n",
    "# Make sure that base model is running on inference mode\n",
    "\n",
    "x = base_model(x, training = False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable = True)\n",
    "# I think we should play with the layers we use here. We should try the setup they have, but maybe add more or different layers depending on how well the model does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ce4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the new top layer of the model\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(), # play with this also\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True), #check this also\n",
    "    metrics = [keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 2 # also play with this\n",
    "print(\"Fitting top layer of model\")\n",
    "model.fit(training_data, epochs = epochs, validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe521ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune entire model\n",
    "base_model.trainable = True\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(1e-5), # can also play with learning rate\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()] #check this -- we have a binary model so it should be ok\n",
    ")\n",
    "\n",
    "epochs = 1 #??\n",
    "print(\"Fitting end-to-end model\")\n",
    "model.fit(training_data, epochs = epochs, validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate model on test data\n",
    "print(\"Test dataset evaluation:\")\n",
    "model.evaluate(testing_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
